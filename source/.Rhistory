rm(list=ls())
library(manipulate)
set.seed(123) # initiate random number generator for reproducability
#------------------------------------------------------------------------------
# 1 generate data
#------------------------------------------------------------------------------
n=50
y = rnorm(n=n, mean=1.0, sd=2.0)
rm(list=ls())
library(manipulate)
set.seed(123) # initiate random number generator for reproducability
#------------------------------------------------------------------------------
# 1 generate data
#------------------------------------------------------------------------------
n=50
y = rnorm(n=n, mean=1.0, sd=2.0)
# examine data:
y
hist(y)
points(y, jitter(rep(0, times=n), factor=10))
# likelihood of first data point:
i = 1
L = dnorm(x=y[i], mean=0, sd=1)
y[i]
L
# plot
curve(dnorm(x, mean=0, sd=1), from=-4, to=6, xlab="y", ylab="p(y)", ylim=c(0, 0.6))
points(y[i],0)
lines(c(y[i],y[i]), c(0, L), col="red")
lines(c(-50,y[i]), c(L, L), col="red")
# dnorm can calculate all p(y_i|mu,sigma) for given parameter combination mu,sigma at once
L = dnorm(x=y, mean=0, sd=1)
# L is a vector now
L
# the likelihood function of all datapoints for a given parameter combination mu,sigma is the product of all single values
# p(y_1,...y_n|mu,sigma)=p(y_1|mu,sigma)*...*p(y_n|mu,sigma)
# This holds because observations are independent
prod(L)
# Better: use log p(y_1,...y_n|mu,sigma)  = log( p(y_1|mu,sigma)*...*p(y_n|mu,sigma)  )) = log p(y_1|mu,sigma) + ... + log p(y_n|mu,sigma)
# log of a product is equal to sum of logs. We minimize the negative log likelihood (NLL) to find model parameters, which is equivalent to maximum likelihood (mathematical convention is minimization instead of maximization)
-sum(log(L))
# visualize likelihood function of all datapoints for given parameters \mu and \sigma
# you can play around with mu and sigma. which combination maximizes likelihood of all datapoints at once?
curve.data <- function(mean, sd)
{
curve(dnorm(x, mean=mean, sd=sd), from=-4, to=6, xlab="y", ylab="p(y)", ylim=c(0, 0.6))
for(i in 1:n){
lines(c(y[i],y[i]),c(0,dnorm(x=y[i], mean=mean, sd=sd)))
}
}
manipulate(curve.data(mean, sd),
mean=slider(-3, 3, step=0.1, initial=0),
sd=slider(0.1,4, step=0.1, initial=1) )
nll.function = function(data, par){ # nll: negative log likelihood
LL = dnorm(x=data, mean=par[1], sd=par[2], log=TRUE) # LL: log-likelihood
NLL = -sum(LL)
return(NLL)
}
nll.function(data=y, par=c(0.0, 1.0))
optim(par=c(0.0, 1.0), # initial guess mu=0, sd=1
fn=nll.function,
data=y)
