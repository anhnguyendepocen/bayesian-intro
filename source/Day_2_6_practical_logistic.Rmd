---
title: "2.6 Practical: logistic regression"
author: "Benjamin Rosenbaum"
date: "April 2, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Statistical model

Suppose we want to measure the effect of a continuous variable on presence / absence data.

E.g. presence of a species in different locations: $y\in[0,1]$ presence (=1) or absence (=0), $x$ = temperature in location.

Statistical model: 
$$
\begin{aligned}
y_i & \sim \text{bernoulli}(p_i) \\ 
\text{logit}(p_i) &= a+b\cdot x_i \\
\text {or, equivalently:}\quad p_i &= \text{inv.logit}(a+b\cdot x_i)
\end{aligned}
$$
$p_i$ is the probability of presence of the species, the distribution of $y_i$ is bernoulli (coin-flip).

We assume a linear relationship of $\text{logit}(p)$ with temperature. (Realistically, a hump-shaped relationship would make more sense.)

$\text{inv.logit}()$ transforms the values of the whole axis to the interval (0,1)

Research question: is there a positive effect of the predictor to the presence of the species?

```{r}
library(boot)
par(mfrow=c(1,2))
curve(logit, from=0, to=1)
curve(inv.logit, from=-10, to=10)
```

Research question: is there a positive effect of the predictor to the presence of the species?

# Setup

```{r}
rm(list=ls())
library(rstan)
library(coda)
library(BayesianTools)
library(boot)
setwd("~/Desktop/teaching Bayes")

rstan_options(auto_write = TRUE)
options(mc.cores = 3) 
```

# Generate data

```{r}
set.seed(123) # initiate random number generator for reproducability
n = 50
x = sort(runif(n, 0, 1))

a = -2
b = 5

p = inv.logit(a+b*x)

y = rbinom(n=n, size=1, prob=p)

plot(x,y)
lines(x,p, lty=2)
``` 

# Stan code and fitting

```{r}
data = list(n=n, 
            x=x, 
            y=y)

stan_code = '
data {
  int  n;
  real x[n];
  int  y[n];
}
parameters {
  real a;  
  real b;  
}
model {
  real p[n];
  // priors
  a ~ normal(0, 10);
  b ~ normal(0, 10);
  // likelihood
  for(i in 1:n){
    p[i] = inv_logit(a+b*x[i]);
    y[i] ~ bernoulli(p[i]);
  }
}
'

stan_model = stan_model(model_code=stan_code)
# save(stan_model, file="stan_model.RData")
# load("stan_model.RData")

fit  = sampling(stan_model,
                data=data,
                chains=3,
                iter=2000,
                warmup=1000
)

print(fit, digits=3, probs=c(0.025, 0.975))

plot(fit)
plot(As.mcmc.list(fit)) # from coda package

posterior=as.matrix(fit)

head(posterior)

correlationPlot(posterior[, 1:2], thin=1)
```

# Predictions 

First, we generate credible intervals for the determinstic model (for p). (90%, but choose as you like)

Later, we generate prediction intervals for the data (for y) using also the stochastic part.

```{r}
x.pred = seq(from=0, to=1, by=0.01)
p.pred = matrix(0, nrow=nrow(posterior), ncol=length(x.pred))

for(i in 1:nrow(posterior)){
  p.pred[i, ] = inv.logit(posterior[i,"a"] + posterior[i,"b"]*x.pred)
}
```


Example: First 100 realizations from the posterior

```{r}
plot(x,y)
for(i in 1:100){
  lines(x.pred, p.pred[i, ], col=adjustcolor("red", alpha.f=0.3))
}
```

Now, the credible intervals using the whole distribution

```{r}
plot(x,y)

p.pred.mean = apply(p.pred, 2, function(x) mean(x)) 
lines(x.pred, p.pred.mean, col="red", lwd=2)

p.pred.q05 = apply(p.pred, 2, function(x) quantile(x, probs=0.05)) 
lines(x.pred, p.pred.q05, col="red", lwd=2, lty=2)

p.pred.q95 = apply(p.pred, 2, function(x) quantile(x, probs=0.95)) 
lines(x.pred, p.pred.q95, col="red", lwd=2, lty=2)
```

Now, we draw predicted data from the bernoulli (=binomial(1)) distribution in the statistical model.

```{r}
y.pred = matrix(0, nrow=nrow(posterior), ncol=length(x.pred))
for(i in 1:nrow(posterior)){
  y.pred[i, ] = rbinom(n=length(x.pred), size=1, p=inv.logit(posterior[i,"a"] + posterior[i,"b"]*x.pred))
}

plot(x,y)
lines(x.pred, p.pred.mean, col="red", lwd=2)
lines(x.pred, p.pred.q05, col="red", lwd=2, lty=2)
lines(x.pred, p.pred.q95, col="red", lwd=2, lty=2)

y.pred.mean = apply(y.pred, 2, function(x) mean(x)) 
lines(x.pred, y.pred.mean, col="blue", lwd=2)

y.pred.q05 = apply(y.pred, 2, function(x) quantile(x, probs=0.05)) 
lines(x.pred, y.pred.q05, col="blue", lwd=2, lty=2)

y.pred.q95 = apply(y.pred, 2, function(x) quantile(x, probs=0.95)) 
lines(x.pred, y.pred.q95, col="blue", lwd=2, lty=2)
```

# Vectorized stan code

Same as above, just coded more efficiently without a for loop

```{r}
stan_code_2 = '
data {
  int n;
  vector[n] x;
  int y[n];
}
parameters {
  real a;  
  real b;  
}
model {
  // priors
  a ~ normal(0, 10);
  b ~ normal(0, 10);
  // likelihood
  y ~ bernoulli(inv_logit(a+b*x));
}
'

stan_model_2 = stan_model(model_code=stan_code_2)
# save(stan_model_2, file="stan_model_2.RData")
# load("stan_model_2.RData")

fit_2  = sampling(stan_model_2,
                  data=data,
                  chains=3,
                  iter=2000,
                  warmup=1000
)

print(fit_2)
```

# Frequentist solution

```{r}
summary(glm(y~x, family=binomial(link="logit")))
```


